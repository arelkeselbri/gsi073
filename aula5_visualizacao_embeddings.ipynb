{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arelkeselbri/gsi073/blob/main/aula5_visualizacao_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8bd4a87",
      "metadata": {
        "id": "e8bd4a87"
      },
      "source": [
        "# Aula 5: Embeddings com modelo *encoder-only* e visualização\n",
        "\n",
        "Nesta prática você vai usar embeddings e verificar visualmente a intuição de que conceitos semânticos estão espacialmente próximos nos embeddings.\n",
        "\n",
        "O roteiro é:\n",
        "\n",
        "1. **Carregar um modelo *encoder-only* para embeddings**.\n",
        "2. **Gerar embeddings por sentença** para uma coleção de documentos.\n",
        "3. **Reduzir a dimensionalidade** e **plotar em 2D** para inspecionar agrupamentos.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27cc542a",
      "metadata": {
        "id": "27cc542a"
      },
      "source": [
        "## 0) Setup do ambiente\n",
        "\n",
        "Vamos instalar dependências e importar bibliotecas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a0e029",
      "metadata": {
        "id": "10a0e029"
      },
      "outputs": [],
      "source": [
        "# Se necessário, instale dependências (descomente e rode)\n",
        "# !pip -q install -U sentence-transformers scikit-learn matplotlib pandas numpy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "\n",
        "# Opcional: para separar sentenças de forma simples (sem libs pesadas)\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2fd4cd6",
      "metadata": {
        "id": "c2fd4cd6"
      },
      "source": [
        "## 1) Mini-dataset\n",
        "Vamos criar uma coleção pequena de documentos, com **rótulos de tópico** (categorias).\n",
        "Você pode substituir por textos reais (artigos, notícias, parágrafos de PDFs, etc.).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7c05e97",
      "metadata": {
        "id": "b7c05e97"
      },
      "outputs": [],
      "source": [
        "docs = [\n",
        "    {\n",
        "        \"id\": \"d1\",\n",
        "        \"label\": \"esporte\",\n",
        "        \"text\": (\n",
        "            \"O time venceu por 2 a 1 no último minuto. \"\n",
        "            \"O técnico elogiou a disciplina tática e a força do elenco. \"\n",
        "            \"A torcida comemorou a classificação no estádio.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"d2\",\n",
        "        \"label\": \"esporte\",\n",
        "        \"text\": (\n",
        "            \"O campeonato começou com jogos equilibrados. \"\n",
        "            \"O atacante marcou dois gols e foi o destaque da rodada. \"\n",
        "            \"A equipe treinou finalizações durante a semana.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"d3\",\n",
        "        \"label\": \"economia\",\n",
        "        \"text\": (\n",
        "            \"A inflação desacelerou neste mês segundo o indicador oficial. \"\n",
        "            \"O banco central sinalizou cautela na política monetária. \"\n",
        "            \"O mercado reagiu com queda nos juros futuros.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"d4\",\n",
        "        \"label\": \"economia\",\n",
        "        \"text\": (\n",
        "            \"A taxa de câmbio variou após o anúncio do pacote fiscal. \"\n",
        "            \"Analistas revisaram projeções de crescimento para o próximo ano. \"\n",
        "            \"O consumo das famílias ainda mostra recuperação lenta.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"d5\",\n",
        "        \"label\": \"tecnologia\",\n",
        "        \"text\": (\n",
        "            \"Um novo modelo de linguagem foi lançado com foco em eficiência. \"\n",
        "            \"Pesquisadores discutem alinhamento e segurança em IA. \"\n",
        "            \"O treinamento usou dados em múltiplos idiomas usado em olimpíadas.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"d6\",\n",
        "        \"label\": \"tecnologia\",\n",
        "        \"text\": (\n",
        "            \"Sistemas de recomendação usam embeddings para medir similaridade. \"\n",
        "            \"A compressão de modelos ajuda a reduzir custo de inferência. \"\n",
        "            \"A comunidade debate benchmarks e avaliação justa.\"\n",
        "        )\n",
        "    },\n",
        "]\n",
        "\n",
        "df_docs = pd.DataFrame(docs)\n",
        "df_docs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e02b79a",
      "metadata": {
        "id": "1e02b79a"
      },
      "source": [
        "## 2) Quebrar documentos em sentenças\n",
        "\n",
        "Vamos transformar cada documento em várias sentenças.  \n",
        "No final, teremos um dataframe com colunas: `doc_id`, `label`, `sentence`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64993676",
      "metadata": {
        "id": "64993676"
      },
      "outputs": [],
      "source": [
        "def split_sentences_pt(text: str) -> list[str]:\n",
        "    # Split simples por ., !, ? mantendo robustez básica\n",
        "    # Para produção, considere spaCy / nltk / blingfire, etc.\n",
        "    parts = re.split(r'(?<=[\\.!\\?])\\s+', text.strip())\n",
        "    # Filtra vazios\n",
        "    return [p.strip() for p in parts if p.strip()]\n",
        "\n",
        "rows = []\n",
        "for d in docs:\n",
        "    for sent in split_sentences_pt(d[\"text\"]):\n",
        "        rows.append({\"doc_id\": d[\"id\"], \"label\": d[\"label\"], \"sentence\": sent})\n",
        "\n",
        "df_sents = pd.DataFrame(rows)\n",
        "df_sents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0604e58",
      "metadata": {
        "id": "d0604e58"
      },
      "source": [
        "## 3) Carregar modelo *encoder-only* para embeddings\n",
        "\n",
        "Para embeddings de sentença, é comum usar modelos já ajustados para similaridade semântica, como os da família **Sentence Transformers**.\n",
        "\n",
        "Exemplos:\n",
        "- `sentence-transformers/all-MiniLM-L6-v2` (inglês, ótimo custo/benefício)\n",
        "- `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` (multilíngue, bom para PT)\n",
        "\n",
        "Aqui usaremos o multilíngue para funcionar bem em português.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3eaf33",
      "metadata": {
        "id": "2a3eaf33"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "model = SentenceTransformer(MODEL_NAME)\n",
        "\n",
        "# Embedding de uma frase (teste rápido)\n",
        "test_vec = model.encode([\"Olá mundo!\"])\n",
        "test_vec.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "465059e7",
      "metadata": {
        "id": "465059e7"
      },
      "source": [
        "## 4) Gerar embeddings para cada sentença\n",
        "\n",
        "Vamos aplicar `model.encode` em lote (batch) para ser eficiente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7a1486b",
      "metadata": {
        "id": "c7a1486b"
      },
      "outputs": [],
      "source": [
        "sentences = df_sents[\"sentence\"].tolist()\n",
        "\n",
        "# normalize_embeddings=True facilita visualização e similaridade por cosseno\n",
        "emb = model.encode(\n",
        "    sentences,\n",
        "    batch_size=32,\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True,\n",
        "    normalize_embeddings=True,\n",
        ")\n",
        "\n",
        "emb.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e608ce1b",
      "metadata": {
        "id": "e608ce1b"
      },
      "source": [
        "Agora vamos guardar esses embeddings no dataframe (uma coluna com array)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb60fc24",
      "metadata": {
        "id": "cb60fc24"
      },
      "outputs": [],
      "source": [
        "df_sents = df_sents.copy()\n",
        "df_sents[\"embedding\"] = list(emb)\n",
        "df_sents.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39fc10aa",
      "metadata": {
        "id": "39fc10aa"
      },
      "source": [
        "## 5) Redução de dimensionalidade para 2D\n",
        "\n",
        "Existem diferentes técnicas para reduzir dimensionalidade de embedding.\n",
        "- **PCA** (linear, rápido; preserva variância global)\n",
        "- **ICA** (linear, busca componentes estatisticamente independentes)\n",
        "- **t-SNE** (não-linear, bom para estrutura local; ótimo para visualização)\n",
        "\n",
        "Frequentemente usa-se **PCA antes do t-SNE** para reduzir a dimensionalidade original para 50 dimensões, o que ajuda em para acelerar o processo e reduzir ruído.\n",
        "\n",
        "A seguir, vamos observar na prática como isso funciona.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec934c4f",
      "metadata": {
        "id": "ec934c4f"
      },
      "outputs": [],
      "source": [
        "X = np.vstack(df_sents[\"embedding\"].to_numpy())  # (n_sentences, dim)\n",
        "\n",
        "# 5.1) PCA direto para 2D\n",
        "pca2 = PCA(n_components=2, random_state=42)\n",
        "X_pca2 = pca2.fit_transform(X)\n",
        "\n",
        "# 5.2) ICA direto para 2D\n",
        "ica2 = FastICA(n_components=2, random_state=42, max_iter=2000)\n",
        "X_ica2 = ica2.fit_transform(X)\n",
        "\n",
        "tsne2 = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=5,           # ajuste conforme o tamanho do dataset (tipicamente 5..50)\n",
        "    learning_rate=\"auto\",\n",
        "    init=\"pca\",\n",
        "    random_state=42,\n",
        ")\n",
        "X_tsne2 = tsne2.fit_transform(X)\n",
        "\n",
        "X_pca2.shape, X_ica2.shape, X_tsne2.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cb9ef23",
      "metadata": {
        "id": "9cb9ef23"
      },
      "source": [
        "## 6) Função de plot 2D (com cores por categoria)\n",
        "\n",
        "Vamos plotar cada sentença como um ponto 2D.  \n",
        "**Interpretação esperada:** sentenças do mesmo tópico tendem a ficar mais próximas, mas não é garantido (dataset pequeno!).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "698c90d9",
      "metadata": {
        "id": "698c90d9"
      },
      "outputs": [],
      "source": [
        "def plot_2d(X2, title: str, df_meta: pd.DataFrame):\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    for label, sub in df_meta.groupby(\"label\"):\n",
        "        idx = sub.index.to_numpy()\n",
        "        plt.scatter(X2[idx, 0], X2[idx, 1], label=label, alpha=0.85)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"dim-1\")\n",
        "    plt.ylabel(\"dim-2\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.2)\n",
        "    plt.show()\n",
        "\n",
        "plot_2d(X_pca2, \"PCA (2D) — embeddings de sentenças\", df_sents)\n",
        "plot_2d(X_ica2, \"ICA (2D) — embeddings de sentenças\", df_sents)\n",
        "plot_2d(X_tsne2, \"t-SNE (2D) — embeddings de sentenças (com pré-PCA 50D)\", df_sents)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a3de83e",
      "metadata": {
        "id": "5a3de83e"
      },
      "source": [
        "## 7) Embedding por documento (agregação)\n",
        "\n",
        "Às vezes você quer um embedding **por documento**, não por sentença.  \n",
        "Uma forma simples é fazer **média** dos embeddings das sentenças do documento (pode funcionar razoavelmente).\n",
        "\n",
        "Depois, repita PCA/t-SNE para visualizar documentos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "028208f3",
      "metadata": {
        "id": "028208f3"
      },
      "outputs": [],
      "source": [
        "# Agrega por doc: média dos vetores das sentenças\n",
        "df_doc_emb = (\n",
        "    df_sents\n",
        "    .groupby([\"doc_id\", \"label\"])[\"embedding\"]\n",
        "    .apply(lambda vs: np.mean(np.vstack(vs), axis=0))\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "X_doc = np.vstack(df_doc_emb[\"embedding\"].to_numpy())\n",
        "\n",
        "# PCA 2D\n",
        "X_doc_pca2 = PCA(n_components=2, random_state=42).fit_transform(X_doc)\n",
        "\n",
        "# t-SNE 2D (sem pré-PCA pois é pequeno)\n",
        "X_doc_tsne2 = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=3,\n",
        "    learning_rate=\"auto\",\n",
        "    init=\"random\",\n",
        "    random_state=42,\n",
        ").fit_transform(X_doc)\n",
        "\n",
        "plot_2d(X_doc_pca2, \"PCA (2D) — embeddings por documento (média)\", df_doc_emb)\n",
        "plot_2d(X_doc_tsne2, \"t-SNE (2D) — embeddings por documento (média)\", df_doc_emb)\n",
        "\n",
        "df_doc_emb[[\"doc_id\", \"label\"]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9152306",
      "metadata": {
        "id": "b9152306"
      },
      "source": [
        "# Exercícios\n",
        "\n",
        "## Exercício A — Substitua o dataset\n",
        "1. Use outro dataset com **50 a 150 documentos**, com **3 a 5 tópicos** (ex.: política, saúde, cultura, tecnologia, esporte).\n",
        "2. Quebre em sentenças.\n",
        "3. Gere embeddings e visualize com PCA e t-SNE.\n",
        "4. Escreva 3 observações:\n",
        "   - Algum tópico formou cluster claro?\n",
        "   - Há sentenças “fora do lugar”? Por quê?\n",
        "   - O que muda ao trocar o modelo (inglês vs multilíngue)?\n",
        "\n",
        "## Exercício B — Variações de t-SNE\n",
        "1. Teste `perplexity` em {5, 10, 30}.\n",
        "2. Teste `init` em {\"pca\", \"random\"}.\n",
        "3. Compare estabilidade visual (semente fixa vs outra).\n",
        "\n",
        "## Exercício C — PCA antes do t-SNE\n",
        "1. Rode t-SNE com e sem PCA prévio (50D).\n",
        "2. Compare tempo e qualidade da separação.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}